{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdjamina/machine_learning/blob/notebook/notebook/deft09_parlement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rpytozcZWfz"
      },
      "source": [
        "# Rapport d'Analyse de Données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYa10wCCcm2F"
      },
      "source": [
        "## Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B8ehPqucvGu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uICzQfIMcs2-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwJw_ZZdcRwc"
      },
      "source": [
        "## Prétraitement des Données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corpus d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_file_path = '../deft09/Corpus d_apprentissage/deft09_parlement_appr_fr.xml'\n",
        "tests_file_path = '../deft09/Corpus de test/deft09_parlement_test_fr.xml'\n",
        "ref_file_path = '../deft09/Données de référence/deft09_parlement_ref_fr.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Path(train_file_path).exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Path(tests_file_path).exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Path(tests_file_path).exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nétoyage des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C7DQZn1ZgIo-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Remplacer les caractères spéciaux\n",
        "# cette permet de remplacer les caractères spéciaux\n",
        "\n",
        "\n",
        "def replace_match(match: re.Match) -> str:\n",
        "\n",
        "    char = match.group(0)\n",
        "    replacements = {'<anonyme />':'ANONYME','’': \"'\",'´': \"'\",'`': \"'\",'‘': \"'\",'«': '\"','»': '\"','“': '\"','”': '\"','–': '-','—': '-','…': ' ',u'\\0xa0': ' ',}\n",
        "\n",
        "    return replacements[char]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### corpus d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../deft09/Corpus d_apprentissage/deft09_parlement_appr_fr_fix.xml\n"
          ]
        }
      ],
      "source": [
        "#Corriger le fichier train\n",
        "pathfile = Path(train_file_path)\n",
        "if not pathfile.exists():\n",
        "    raise FileNotFoundError(f\"{pathfile} not found\")\n",
        "\n",
        "pathfile_fix = pathfile.parent / f\"{pathfile.stem}_fix{pathfile.suffix}\"\n",
        "\n",
        "with pathfile.open('r') as f:\n",
        "    pattern = re.compile(r'<anonyme\\s*/>|[’´`‘«»“”–—…]')\n",
        "    content = re.sub(pattern, replace_match, f.read()).strip()\n",
        "    with pathfile_fix.open('w') as f2:\n",
        "        f2.write(content)\n",
        "train_file_path = str(pathfile_fix)\n",
        "print(train_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### corpus de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../deft09/Corpus de test/deft09_parlement_test_fr_fix.xml\n"
          ]
        }
      ],
      "source": [
        "#Corriger le fichier test\n",
        "pathfile = Path(tests_file_path)\n",
        "if not pathfile.exists():\n",
        "    raise FileNotFoundError(f\"{pathfile} not found\")\n",
        "\n",
        "pathfile_fix = pathfile.parent / f\"{pathfile.stem}_fix{pathfile.suffix}\"\n",
        "\n",
        "with pathfile.open('r') as f:\n",
        "    pattern = re.compile(r'<anonyme\\s*/>|[’´`‘«»“”–—…]')\n",
        "    content = re.sub(pattern, replace_match, f.read()).strip()\n",
        "    with pathfile_fix.open('w') as f2:\n",
        "        f2.write(content)\n",
        "tests_file_path = str(pathfile_fix)\n",
        "print(tests_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4Sxa_3OftGh"
      },
      "source": [
        "### Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rMr9YsIZcRB1"
      },
      "outputs": [],
      "source": [
        "from lxml import etree as et\n",
        "\n",
        "#Parser le fichier xml\n",
        "def parser(pathfile: str) -> list:\n",
        "\n",
        "    # Parser le fichier XML avec lxml pour plus de performance\n",
        "    tree = et.parse(pathfile)\n",
        "\n",
        "    # Récupérer la racine du fichier XML\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Utiliser tqdm pour afficher la barre de progression\n",
        "    for doc in root.findall('.//doc'):\n",
        "        id_doc: str = doc.attrib['id']\n",
        "        parti = None\n",
        "        if doc.find('.//PARTI') is not None:\n",
        "            parti = doc.find('.//PARTI').attrib['valeur']\n",
        "        text = \" \".join(p.text for p in doc.findall('.//p') if p.text)\n",
        "\n",
        "        yield id_doc, parti, text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### corpus d'apprentissage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>parti</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2_fr:1</td>\n",
              "      <td>Verts-ALE</td>\n",
              "      <td>Monsieur le Président, j'ai toujours fait preu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2_fr:2</td>\n",
              "      <td>PPE-DE</td>\n",
              "      <td>Madame la Présidente, chers collègues, à l'app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2_fr:3</td>\n",
              "      <td>Verts-ALE</td>\n",
              "      <td>Je voudrais savoir si l'Union européenne, à la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2_fr:4</td>\n",
              "      <td>PSE</td>\n",
              "      <td>Madame la Présidente, au nom des ANONYME de la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2_fr:5</td>\n",
              "      <td>PSE</td>\n",
              "      <td>Monsieur le Président, chers collègues, Monsie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id      parti                                               text\n",
              "0  2_fr:1  Verts-ALE  Monsieur le Président, j'ai toujours fait preu...\n",
              "1  2_fr:2     PPE-DE  Madame la Présidente, chers collègues, à l'app...\n",
              "2  2_fr:3  Verts-ALE  Je voudrais savoir si l'Union européenne, à la...\n",
              "3  2_fr:4        PSE  Madame la Présidente, au nom des ANONYME de la...\n",
              "4  2_fr:5        PSE  Monsieur le Président, chers collègues, Monsie..."
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "data_train = pd.DataFrame(parser(str(train_file_path)), columns=['id', 'parti', 'text'])\n",
        "data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### corpus de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Monsieur le Président, l'accès à des médias li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Monsieur le Président, j'ai un point de vue di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Monsieur le Président, Monsieur le Commissaire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nous ne pouvons soutenir cette tentative d'éri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Monsieur le Président, ce court débat se dérou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "index                                                   \n",
              "1      Monsieur le Président, l'accès à des médias li...\n",
              "2      Monsieur le Président, j'ai un point de vue di...\n",
              "3      Monsieur le Président, Monsieur le Commissaire...\n",
              "4      Nous ne pouvons soutenir cette tentative d'éri...\n",
              "5      Monsieur le Président, ce court débat se dérou..."
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tests = pd.DataFrame([(id_doc,text) for id_doc,_,text in parser(str(tests_file_path))], columns=['index', 'text'])\n",
        "data_tests = data_tests.set_index('index')\n",
        "\n",
        "data_tests.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### données références"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parti</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ELDR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GUE-NGL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PPE-DE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GUE-NGL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PPE-DE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         parti\n",
              "index         \n",
              "1         ELDR\n",
              "2      GUE-NGL\n",
              "3       PPE-DE\n",
              "4      GUE-NGL\n",
              "5       PPE-DE"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_ref = pd.read_csv(ref_file_path, sep='\\t', header=None, names=['index', 'parti'])\n",
        "data_ref = data_ref.set_index('index')\n",
        "\n",
        "data_ref.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### prétraitement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### chargement du modèle spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### prerequis\n",
        "\n",
        "* installation des packages\n",
        "\n",
        "```bash\n",
        "pip install spacy\n",
        "```    \n",
        "\n",
        "* téléchargement du modèle\n",
        "\n",
        "```bash\n",
        "python -m spacy download fr_core_news_lg\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "disable = [\"vectors\", \"senter\", \"textcat\"]\n",
        "\n",
        "nlp = spacy.load('fr_core_news_lg', disable=disable)\n",
        "\n",
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "\n",
        "def lemmatization(text: str, stop_words=True, pos:list = None) -> list:\n",
        "\n",
        "    #doc = nlp(text)\n",
        "\n",
        "    document = []\n",
        "\n",
        "    for token in nlp(text):\n",
        "        is_stop= any([token.lemma_ in STOP_WORDS,\n",
        "                       token.text in STOP_WORDS,\n",
        "                       token.is_stop,\n",
        "                       token.is_punct,\n",
        "                       token.is_space,\n",
        "                       token.is_digit\n",
        "                       ])\n",
        "        if ( stop_words and is_stop):\n",
        "            continue\n",
        "        if pos and token.pos_ not in pos:\n",
        "            continue\n",
        "        document.append(token.lemma_.lower())\n",
        "\n",
        "    # return document, entities\n",
        "    return \" \".join(document)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'encourager permettre éviter pouvoir soutenir répondre soulever exprimer soumettre voir retarder devo'"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatization(data_train['text'][0],pos=['VERB'])[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdyJi2AtZeSv"
      },
      "source": [
        "## Entraînement du Modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### corpus d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Verts-ALE', 'PPE-DE', 'Verts-ALE', 'PSE', 'PSE'], dtype=object)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = data_train['parti'].to_numpy()\n",
        "y_train[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([\"monsieur président preuve scepticisme comportement moraliste policier encourager carrément délation permettre éviter cas fraude biais création instrument contrôle envahissant rapport pouvoir certainement groupe soutenir conviction rapport président napolitano modification règlement proposition décision répondre sérieusement préoccupation soulever récemment m. dell' alba dernier exprimer soumettre député contrôle excessif arbitraire voir aucun raison retarder davantage décision abus devoir produire parlement européen député disposer large possibilité défendre procédure interne transparent clair évidemment chose facile devoir confiance travail futur olaf devoir faciliter action manière pouvoir réagir crédible cas instrumentalisation pouvoir faire preuve efficacité agir répondre genre situation aujourd'hui mme theato m. bösch\",\n",
              "       'monsieur président cher collègue approche moment sombre année réjouissant évoquer été heure été vouloir attirer attention rituel réglage montre répéter printemps automne utilité diviser opinion contacter éleveur bétail souligner important assurer bien-être vache laitier -ce production laitier sérénité ruminant troubler maladie vache fou falloir accroître stress perturber rythme habituel vache changement rythme prendre jour difficulté exister agriculture automne battage heure indique humidité matinal devoir disparaître surprise nature conforme directive rythme naturel animal dynamisme homme dépendre partiellement luminosité perturber cause problème supplémentaire considérer communiqué commission établir irréfutable nécessité heure été estime maintien pratique reconsidérer vite discutable heure devoir terminer temps mois novembre souvenir refroidir europe nord blanc neige raisonnable mettre terme heure fin septembre mois début croire totalement opposer heure été présente côté positif vouloir demander commission évaluation critique nécessité maintien ultérieur heure été pouvoir passer heure été pourtant prêt renoncer temps estival chaud heureusement homme politique décider',\n",
              "       'vouloir savoir union européen lumière information transmettre intervenir auprès nations uni fournir minimum réponse constructif statut venir peuple sahraoui année promettre référendum discussion mener impasse créer situation difficile beaucoup vivre camp réfugié union européen travers monsieur président intervenir lettre auprès nations uni exprimer préoccupation important dossier',\n",
              "       'monsieur président nom anonyme commission industrie vouloir faire bref commentaire commission mérite vaincre inaction contribuer apport réponse politique parlement demande action effectif cohérent secteur savoir cause accident multiplier aggraver technologie disposer découler écart concurrentiel construction naval entraîner diminution qualité gestion économique absurde flotte âgé point culminer traduire stratégie réduction draconien entretien équipage accident expliquer non âge type navire manque qualité armateur opérateur recourir moyen disponible réduire coût moyen mentionner ici pavillon complaisance permissivité autorité portuaire complicité société classification problème sécurité transport passer pénalisation judicieux contrevenant pénalisation comporte coût répartir ensemble secteur pénaliser secteur européen accord imposition seuil préjudice personnel décès préjudice matériel état membre possibilité relever limite accord idée qualité société classification découler dimension effectif inspecteur préférer guider conséquence certification régime responsabilité civil compatible risque permettre faire commentaire portugal mentionner ici portugal soutenir modification directive 94/54 accord suppression société classification petit pays engagement société classification évaluer aide critère commun nombre accident incident détention navire inspecter certifier origine pollution illusoire espérer réduction nombre accident coordination international travers compromis politique entreprise renouveler logique exploitation',\n",
              "       'monsieur président cher collègue monsieur commissaire plupart accord parvenir bon résultat comité conciliation nom groupe anonyme vouloir remercier sincèrement rapporteur engagement dossier bon collaboration collègue plénière confirmer résultat accomplir supplémentaire transparence sécurité domaine production aliment animal indépendamment proposition règlement exister rapport traire aliment animal parlement conseil commission actuellement négociation projet règlement sous-produit animal non destiner consommation humain spécialement catégorie utilisation futur déchet table provenir production aliment rester utiliser sous-produit travailler procédé sûr obligation strict contrôle effectif étape transformation alimentation haut qualité destiner élevage porcin volaille autant résultat scientifique modifier donne futur espérer parlement commission conseil montrer prêt compromis cours procédure discuter soir'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train = data_train['text'].to_numpy()\n",
        "x_train[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modèle de classification "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import Memory\n",
        "mem = Memory(location=\"/tmp/cachedir\", verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tTfidVec = ('TfidfVectorizer', TfidfVectorizer(lowercase=False, max_df=0.95, min_df=10,sublinear_tf=True,preprocessor=lemmatization))\n",
        "\n",
        "pipelines = {\n",
        "    'LinearSVC': Pipeline([tTfidVec, ('LinearSVC', LinearSVC(max_iter=10000, dual=\"auto\")) ])\n",
        "    ,'MultinomialNB' :Pipeline([tTfidVec,('MultinomialNB', MultinomialNB()) ])\n",
        "    , 'DecisionTreeClassifier': Pipeline([tTfidVec,('DecisionTreeClassifier', DecisionTreeClassifier()) ])\n",
        "\n",
        "}\n",
        "\n",
        "models = ((title,clf.fit(x_train, y_train)) for title,clf in pipelines.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### entrainement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Sauvegarder les modèles\n",
        "from joblib import dump, load\n",
        "for title, model in models:\n",
        "    dump(model, f'{title}.joblib')\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-PEbV1wceqc"
      },
      "source": [
        "## Évaluation du Modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0YZ040Sci_z"
      },
      "outputs": [],
      "source": [
        "x_test = data_tests['text'].apply(lambda x : lemmatization(x,pos=pos)).to_numpy()\n",
        "y_test = data_ref['parti'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "for title, model in models:\n",
        "    predictions = model.predict(x_test)\n",
        "    print(title)\n",
        "    print(metrics.classification_report(y_test, predictions, output_dict=False))\n",
        "    print('confusion_matrix')\n",
        "    print(metrics.confusion_matrix(y_test, predictions))\n",
        "    print('accuracy_score')\n",
        "    print(metrics.accuracy_score(y_test, predictions))\n",
        "    print('precision_score')\n",
        "    print(metrics.precision_score(y_test, predictions, average='macro'))\n",
        "    print('recall_score')\n",
        "    print(metrics.recall_score(y_test, predictions, average='macro'))\n",
        "    print('f1_score')\n",
        "    print(metrics.f1_score(y_test, predictions, average='macro'))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### affichage des résultats\n",
        "\n",
        "sources: https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Set-up 2x2 grid for plotting.\n",
        "fig, sub = plt.subplots(2, 2)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "X0, X1 = x_test[:, 0], x_test[:, 1]\n",
        "\n",
        "for clf, title, ax in zip(models.values(), models.keys(), sub.flatten()):\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        x_test,\n",
        "        response_method=\"predict\",\n",
        "        cmap=plt.cm.coolwarm,\n",
        "        alpha=0.8,\n",
        "        ax=ax,\n",
        "        xlabel='discours',\n",
        "        ylabel='parti',\n",
        "    )\n",
        "    ax.scatter(X0, X1, c=y_test, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW_DQpEmcjS9"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPYPFUdYqwyIF8dZxc8IoPO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
